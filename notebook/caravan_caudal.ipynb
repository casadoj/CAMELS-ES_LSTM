{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31386c2e-5cc8-4833-a552-4a29ac9f114f",
   "metadata": {},
   "source": [
    "# Caravan-ESP: preprocesar caudal\n",
    "***\n",
    "\n",
    "***Autor:** Jesús Casado Rodríguez*<br>\n",
    "***Fecha:** 05-08-2023*<br>\n",
    "\n",
    "**Introducción:**<br>\n",
    "Para compilar los datos de Caravan son necesarias dos tablas:\n",
    "* Una tabla con el ID, longitud, latitud, nombre y país de cada una de las estaciones. Las coordenadas deben de estar en el sistema WGS84 (EPSG:4326).\n",
    "* Una tabla con la serie temporal de caudal diario de cada una de las estaciones.\n",
    "\n",
    "En este _notebook_ se cargan las estaciones seleccionadas para incluir en el conjunto de datos Caravan-ESP, y sus series de caudal diario. Las series de caudal se transforma en caudal específico (caudal dividido por área de la cuenca vertiente, mm/d) y se exportan para su posterior utilización en la generación de Caravan-ESP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14788961-546a-4c63-9339-6af07d280ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9ebd8-b824-4a53-8643-164ba658b6c8",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08e3e435-5c4f-4434-bf67-41db6e6ec422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta donde se ubican los datos del Anurio de Aforos\n",
    "path_in = '../data/anuario_aforos/'\n",
    "\n",
    "# cuencas\n",
    "catchments = 'all' #'cantabrico'\n",
    "\n",
    "# inicio y fin del periodo de estudio\n",
    "start = '1980-10-01'\n",
    "end = '2020-09-30'\n",
    "\n",
    "# tamaño mínimo y máximo de la cuenca\n",
    "area_min = 100 # km²\n",
    "area_max = None # km²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4e350-e502-4d1c-9255-6e998ee9227d",
   "metadata": {},
   "source": [
    "## Procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b95549b-39ca-49e3-82d3-32f8873c0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(catchments, str):\n",
    "    if catchments == 'all':\n",
    "        catchments= [dir for dir in os.listdir(path_in) if os.path.isdir(os.path.join(path_in, dir))]\n",
    "    else:\n",
    "        catchments = [catchments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb9873b-d7a0-4fc1-9039-107c66d7e2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebfe7d5aa9b499bbb549a5008285351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUADIANA no tiene la tabla de estaciones seleccionadas\n"
     ]
    }
   ],
   "source": [
    "for catchment in tqdm(catchments):\n",
    "\n",
    "    try:\n",
    "        # cargar estaciones\n",
    "        stns = pd.read_csv(f'{path_in}{catchment}/estaciones_seleccion.csv', index_col='indroea')\n",
    "        stns.index = stns.index.astype(str)\n",
    "    except:\n",
    "        print(f'{catchment} no tiene la tabla de estaciones seleccionadas')\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # cargar series de caudal\n",
    "        dis = pd.read_parquet(f'{path_in}{catchment}/caudal.parquet', columns=stns.index)\n",
    "        dis = dis.loc[start:end,:]\n",
    "    except:\n",
    "        print(f'{catchment} no tiene la tabla con las series diarias de caudal')\n",
    "        continue\n",
    "\n",
    "    # calcular caudal específico\n",
    "    dis_sp = dis / stns.suprest * 3600 * 24 * 10e-3 # mm/d\n",
    "    dis_sp.index.name = 'date'\n",
    "\n",
    "    # unir al resto de cuencas\n",
    "    if 'stations' not in locals():\n",
    "        stations = stns\n",
    "    else:\n",
    "        stations = pd.concat((stations, stns), axis=0)\n",
    "    if 'discharge_sp' not in locals():\n",
    "        discharge_sp = dis_sp\n",
    "    else:\n",
    "        discharge_sp = pd.concat((discharge_sp, dis_sp), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a89e80-6c42-4971-a450-60e06c70f94e",
   "metadata": {},
   "source": [
    "## Exportar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5839ac85-f9aa-4ad3-9840-d986e32030c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(catchments) == 1:\n",
    "    path_out = f'{path_in}/{catchments[0]}/'\n",
    "    discharge_sp.to_csv(f'{path_out}/caravan_caudal_especifico.csv', float_format='%.3f')\n",
    "elif len(catchments) > 1:\n",
    "    path_out = path_in\n",
    "    stations.to_csv(f'{path_out}/caravan_estaciones.csv', float_format='%.3f')\n",
    "    discharge_sp.to_csv(f'{path_out}/caravan_caudal_especifico.csv', float_format='%.3f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
