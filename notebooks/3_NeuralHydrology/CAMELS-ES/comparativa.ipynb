{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcba7aa9-ae8f-4ad1-836c-ebb2e2420596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "from neuralhydrology.utils.config import Config\n",
    "\n",
    "os.chdir('../')\n",
    "from model_utils import *\n",
    "os.chdir('CAMELS-ES/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0c48e4-afed-432f-8b9d-6585a95173a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e3401fe87b4d35b71b650fc66ed17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAMELS-ES_base      \tmejor época: 21\t\tKGE = 0.577\n",
      "CAMELS-ES_batch128  \tmejor época: 30\t\tKGE = 0.502\n",
      "CAMELS-ES_batch526  \tmejor época: 7\t\tKGE = 0.561\n",
      "CAMELS-ES_clip0.8   \tmejor época: 22\t\tKGE = 0.601\n",
      "CAMELS-ES_clipNone  \tmejor época: 30\t\tKGE = 0.572\n",
      "CAMELS-ES_drop03    \tmejor época: 28\t\tKGE = 0.549\n",
      "CAMELS-ES_drop05    \tmejor época: 30\t\tKGE = 0.542\n",
      "CAMELS-ES_end2      \tmejor época: 14\t\tKGE = 0.518\n",
      "CAMELS-ES_end3      \tmejor época: 12\t\tKGE = 0.581\n",
      "CAMELS-ES_end       \tmejor época: 25\t\tKGE = 0.591\n",
      "CAMELS-ES_hidden032 \tmejor época: 24\t\tKGE = 0.544\n",
      "CAMELS-ES_hidden128 \tmejor época: 13\t\tKGE = 0.593\n",
      "CAMELS-ES_overfit1  \tmejor época: 7\t\tKGE = 0.510\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\CAMELS-ES_overfit1_1209_174821\\\\train\\\\model_epoch007\\\\train_results.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0:<20}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mmejor época: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mKGE = \u001b[39m\u001b[38;5;132;01m{2:.3f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, epoch, df\u001b[38;5;241m.\u001b[39mmedian()\u001b[38;5;241m.\u001b[39mmax()))\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 20\u001b[0m     _, rend \u001b[38;5;241m=\u001b[39m \u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperiod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     compare\u001b[38;5;241m.\u001b[39mloc[name, period] \u001b[38;5;241m=\u001b[39m rend\u001b[38;5;241m.\u001b[39mmedian()\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mC:\\GitHub\\TFM\\notebooks\\3_NeuralHydrology\\model_utils.py:50\u001b[0m, in \u001b[0;36mget_results\u001b[1;34m(run_dir, period, epoch)\u001b[0m\n\u001b[0;32m     45\u001b[0m path \u001b[38;5;241m=\u001b[39m run_dir \u001b[38;5;241m/\u001b[39m period \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# time series\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# with open(path / f'{period}_results.p', 'rb') as fp:\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m#     results = pickle.load(fp)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mperiod\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_results.p\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# metrics\u001b[39;00m\n\u001b[0;32m     53\u001b[0m metrics \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mperiod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\neuralhydrology\\lib\\site-packages\\pandas\\io\\pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    197\u001b[0m \n\u001b[0;32m    198\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramFiles\\Anaconda3\\envs\\neuralhydrology\\lib\\site-packages\\pandas\\io\\common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\CAMELS-ES_overfit1_1209_174821\\\\train\\\\model_epoch007\\\\train_results.p'"
     ]
    }
   ],
   "source": [
    "runs = [Path(x) for x in glob.glob('runs/CAMELS-ES*') if os.path.isdir(x)]\n",
    "names = [Config(Path(run) / 'config.yml').experiment_name for run in runs]\n",
    "\n",
    "compare = pd.DataFrame(index=names, columns=['train', 'validation', 'test'])\n",
    "for run in tqdm(runs):\n",
    "    cfg = Config(Path(run) / 'config.yml')\n",
    "    name = cfg.experiment_name\n",
    "    # extraer el rendimiento de cada época y muestra\n",
    "    df = pd.DataFrame(columns=range(1, cfg.epochs + 1))\n",
    "    for epoch in df.columns:\n",
    "        try:\n",
    "            _, df[epoch] = get_results(Path(run), 'validation', epoch=epoch)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    epoch = df.median().idxmax()\n",
    "    print('{0:<20}\\tmejor época: {1}\\t\\tKGE = {2:.3f}'.format(name, epoch, df.median().max()))\n",
    "    \n",
    "    for period in ['train', 'validation', 'test']:\n",
    "        _, rend = get_results(Path(run), period, epoch=epoch)\n",
    "        compare.loc[name, period] = rend.median().values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b131ac-f699-4217-8e88-15204d122784",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ee03c-93e2-4ba1-9cd4-eb81baec26ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
