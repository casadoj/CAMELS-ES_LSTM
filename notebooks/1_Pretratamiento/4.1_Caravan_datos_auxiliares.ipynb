{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31386c2e-5cc8-4833-a552-4a29ac9f114f",
   "metadata": {},
   "source": [
    "# Caravan-ESP: datos auxiliares\n",
    "***\n",
    "\n",
    "***Autor:** Jesús Casado Rodríguez*<br>\n",
    "***Fecha:** 16-09-2023*<br>\n",
    "\n",
    "**Introducción:**<br>\n",
    "Para compilar los datos de Caravan son necesarias dos tablas:\n",
    "* Una tabla con el ID, longitud, latitud, nombre y país de cada una de las estaciones. Las coordenadas deben de estar en el sistema WGS84 (EPSG:4326).\n",
    "* Una tabla con la serie diaria de caudal específico de cada una de las estaciones.\n",
    "\n",
    "Además, para publicar el conjunto de datos en Caravan es necesario incluir una capa de polígonos con la cuenca de cada una de las estaciones.\n",
    "\n",
    "En este _notebook_ se cargan las estaciones seleccionadas para incluir en el conjunto de datos Caravan-ESP, y sus series de caudal diario. Las series de caudal se transforma en caudal específico (caudal dividido por área de la cuenca vertiente, mm/d) y se exportan para su posterior utilización en la generación de Caravan-ESP.\n",
    "\n",
    "**Por hacer:**<br>\n",
    "En este _notebook_ se eliminan ciertas estaciones del Anuario de Aforos porque se ha visto que las series no son buenas. Habría que traspasar estas estaciones al _notebook_ inicial en el que se hace la selección de estaciones del Anuario de Aforos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14788961-546a-4c63-9339-6af07d280ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cf\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from anuario_aforos import plot_caudal\n",
    "from funciones import dividir_estaciones, dividir_periodo_estudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9ebd8-b824-4a53-8643-164ba658b6c8",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b0607-afd0-4d92-881f-e49ac0aac7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yml\", \"r\", encoding='utf8') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "# ruta donde se ubican los datos del Anurio de Aforos\n",
    "path_anuario = Path('../../data/anuario_aforos/')\n",
    "path_camels = Path(cfg['rutas'].get('caravan', '../../data/CAMELS-ES/'))\n",
    "\n",
    "# inicio y fin del periodo de estudio\n",
    "start = cfg['periodo'].get('inicio', None)\n",
    "end = cfg['periodo'].get('final', None)\n",
    "start, end = [pd.to_datetime(i) for i in [start, end]]\n",
    "\n",
    "# tamaño de las muestras de entrenamiento y validación\n",
    "train_size = cfg.get('train_size', .6)\n",
    "assert 0 < train_size <= 1., '\"train_size\" debe de ser un valor entre 0 y 1'\n",
    "val_size = cfg.get('val_size', .2)\n",
    "assert 0 < val_size <= 1., '\"train_size\" debe de ser un valor entre 0 y 1'\n",
    "if train_size + val_size > 1:\n",
    "    val_size = 1 - train_size\n",
    "    print(f'El valor de \"val_size\" fue truncado a {val_size:.2f}')\n",
    "seed = cfg.get('seed', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef038128-95f5-4dfa-aa37-9c13293f07de",
   "metadata": {},
   "source": [
    "## Datos\n",
    "### Atributos CARAVAN-ESP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53b306-84cb-438f-b9f3-6049a4300519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar tabla de atributos de Caravan\n",
    "atributos = pd.read_csv(path_camels / 'attributes/attributes_caravan_es.csv', index_col=0)\n",
    "atributos.index = atributos.index.astype(str)\n",
    "# atributos.index = [id.split('_')[-1] for id in atributos.index]\n",
    "\n",
    "print('nº de estaciones:\\t{0}\\nnº de atributos:\\t{1}'.format(*atributos.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110ac86-5888-404b-af9c-5856e4bd4255",
   "metadata": {},
   "source": [
    "### Estaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30a810-1e33-4223-8f2d-69989e91dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar estaciones\n",
    "estaciones = gpd.read_file(path_anuario / 'GIS/estaciones.shp')\n",
    "estaciones.set_index('indroea', drop=True, inplace=True)\n",
    "estaciones = estaciones.loc[atributos.index]\n",
    "estaciones[['ini_cal', 'fin_cal']] = estaciones[['ini_cal', 'fin_cal']].astype(int)\n",
    "\n",
    "n_estaciones = estaciones.shape[0]\n",
    "print('nº de estaciones en la capa de puntos:\\t{0}'.format(n_estaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e567b5-d13e-44e7-ab91-aed1dc244167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!\n",
    "estaciones.loc['9030', 'fin_cal'] = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966089e-7583-421d-8114-0901d7d394b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar estaciones \n",
    "# borrar = ['2048', '3233', '3251', '3255', '4207', '4212', '4214',\n",
    "#           '5140', '7112', '7121', '8027', '8092', '8140', '8148', '9087', '9255']\n",
    "estaciones = estaciones.loc[~estaciones.index.isin(borrar)]\n",
    "\n",
    "n_estaciones = estaciones.shape[0]\n",
    "print('nº de estaciones en la capa de puntos:\\t{0}'.format(n_estaciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd4b68-11c6-4373-b0a4-5caeeafc3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exportar\n",
    "# estaciones.index.name = 'gauge_id'\n",
    "# estaciones.to_csv(path_camels / f'stations_camelsesp_{n_estaciones}.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c20b6-943f-4ea2-a69c-fa8298154758",
   "metadata": {},
   "outputs": [],
   "source": [
    "estaciones_lisflood = gpd.read_file(path_anuario / 'GIS' / 'estaciones_seleccion_EFASv5.shp')\n",
    "estaciones_lisflood.set_index('indroea', drop=True, inplace=True)\n",
    "estaciones_lisflood = estaciones_lisflood.loc[estaciones.index]\n",
    "estaciones_lisflood.to_file(path_anuario / 'GIS' / 'estaciones_seleccion_LISFLOOD.shp', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b9f37b-e664-47bf-8521-240d4a184875",
   "metadata": {},
   "source": [
    "**Definir estaciones de entrenamiento y validación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263dc64-1083-4832-aec4-1014772021f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # crear listados de estaciones de entrenamiento, validación y evaluación\n",
    "# cuencas = ['CANTABRICO', 'GALICIA', 'MINHO', 'DUERO', 'TAJO', 'GUADIANA', 'GUADALQUIVIR', 'SEGURA', 'JUCAR', 'EBRO']\n",
    "Cuencas = estaciones.cuenca.unique()\n",
    "ids = estaciones.loc[estaciones.cuenca.isin(Cuencas)].index.to_list()\n",
    "basins = dividir_estaciones(ids,\n",
    "                            cal=train_size,\n",
    "                            val=val_size,\n",
    "                            path=path_camels,\n",
    "                            seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e24a5-5035-45e8-89f5-5b0f1a638c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cuenca in Cuencas:\n",
    "#     basins_cuenca = dividir_estaciones(estaciones.loc[estaciones.cuenca == cuenca].index.to_list(),\n",
    "#                                        cal=train_size,\n",
    "#                                        val=val_size,\n",
    "#                                        path=Path(f'../3_NeuralHydrology/{cuenca}/'),\n",
    "#                                        seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fbba04-21b2-4d30-a9c9-5ce84150a7b5",
   "metadata": {},
   "source": [
    "### Subcuencas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f94b11-57b0-476c-a45c-1ac221423154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar polígonos de las cuencas de Caravan\n",
    "cuencas = gpd.read_file(path_anuario / 'GIS/subcuencas_epsg4326.shp')\n",
    "cuencas.set_index('gauge_id', drop=True, inplace=True)\n",
    "\n",
    "# recortar cuencas según la tabla de atributos\n",
    "cuencas = cuencas.loc[estaciones.index, :]\n",
    "cuencas.index.name = 'gauge_id'\n",
    "\n",
    "# generar nuevos campos\n",
    "cuencas['gauge_name'] = estaciones.lugar\n",
    "cuencas['gauge_lat'] = estaciones.latwgs84\n",
    "cuencas['gauge_lon'] = estaciones.longwgs84\n",
    "cuencas['country'] = 'Spain'\n",
    "cuencas.area_skm = cuencas.area_skm.astype(int)\n",
    "\n",
    "# eliminar campos\n",
    "cuencas.drop(['HydroID'], axis=1, inplace=True)\n",
    "\n",
    "# reordenar\n",
    "cuencas = cuencas[['gauge_name', 'gauge_lat', 'gauge_lon', 'country', 'area_skm', 'geometry']]\n",
    "\n",
    "n_cuencas = cuencas.shape[0]\n",
    "print('nº de cuencas en la capa de polígonos:\\t{0}'.format(n_cuencas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa960259-20bd-454c-891b-a62259defb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar\n",
    "cuencas.to_file(path_camels / f'shapefiles/catchments_camelsesp_{n_cuencas}.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7376adec-9b58-41ab-8684-648b96bfe77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot estaciones\n",
    "proj = ccrs.PlateCarree()\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': proj})\n",
    "ax.add_feature(cf.NaturalEarthFeature('physical', 'land', '50m', edgecolor=None, facecolor='lightgray'), zorder=0)\n",
    "ax.set_extent([-9.5, 3.5, 36, 44.5], crs=proj)\n",
    "cuencas.plot(ax=ax, facecolor='none', edgecolor='w', linewidth=0.4);\n",
    "ax.scatter(estaciones.geometry.x, estaciones.geometry.y, c='steelblue', s=5, alpha=1, label='Anuario')\n",
    "ax.set_title('Estaciones Anuario de Aforos')\n",
    "ax.axis('off');\n",
    "\n",
    "# plt.savefig(f'{path_plots}estaciones.jpg', dpi=300, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179a9e12-9301-4529-943a-d296cb317ae7",
   "metadata": {},
   "source": [
    "### Caudal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469aa8de-b02b-4ca2-b924-78f7d64477b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar series de caudal\n",
    "caudal = pd.read_parquet(path_anuario / 'caudal.parquet', columns=estaciones.index)\n",
    "caudal = caudal.loc[start:end, estaciones.index]\n",
    "\n",
    "caudal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe755f-4a9e-49af-b150-95ee81f4d2fc",
   "metadata": {},
   "source": [
    "**Series de caudal específico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819e40e-99e7-4760-80f0-b51fc0c1459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular caudal específico\n",
    "caudal_esp = caudal / estaciones.suprest * 3.6 * 24 # mm/d\n",
    "caudal_esp.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9253f7-af75-47df-a77e-17972a843044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar\n",
    "n_series = caudal_esp.shape[1]\n",
    "# caudal_esp.to_parquet(path_out / f'specific_discharge_camelsesp_{n_series}.parquet')\n",
    "caudal_esp.to_csv(path_camels / f'specific_discharge_camelsesp_{n_series}.csv', float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678bc0b-8f8b-407d-9397-941879197354",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "ax.scatter(estaciones.suprest, caudal_esp.mean(), s=4, alpha=.5)\n",
    "ax.set(xlabel='area (km²)',\n",
    "       ylabel='caudal específico (mm/d)');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ef4d5-c41c-45d9-b40a-08168a20f2a7",
   "metadata": {},
   "source": [
    "**Definir periodos de calentamiento, validación y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07378972-1b34-48e3-90e0-dfbf3d5724a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodos_ds = {}\n",
    "for stn in ids:\n",
    "    if stn in basins['train']:\n",
    "        cal, val = .6, 0\n",
    "    elif stn in basins['validation']:\n",
    "        cal, val = 0, .6\n",
    "    elif stn in basins['test']:\n",
    "        cal, val = 0, 0\n",
    "    else:\n",
    "        continue\n",
    "    periodos_ds[stn] = dividir_periodo_estudio(caudal[stn], *estaciones.loc[stn, ['ini_cal', 'fin_cal']], cal, val)\n",
    "periodos_ds = xr.Dataset(periodos_ds).to_array(dim='id')\n",
    "\n",
    "# definir periodos de calibración, validación y evaluación para cada estación\n",
    "# periodos_ds = xr.Dataset({stn: dividir_periodo_estudio(caudal[stn], *estaciones.loc[stn, ['ini_cal', 'fin_cal']]) for stn in caudal.columns}).to_array(dim='id')\n",
    "\n",
    "# reorganizar el diccionario\n",
    "periodos_dct = {}\n",
    "for p in periodos_ds.period.data:\n",
    "    periodos_dct[p] = {}\n",
    "    for id in basins[p]: #periodos_ds.id.data:\n",
    "        periodos_dct[p][id] = {f'{key}_dates': [date] for key, date in periodos_ds.sel(period=p, id=id).to_pandas().to_dict().items()}\n",
    "\n",
    "# guardar los periodos como pickle\n",
    "for key, dct in periodos_dct.items():\n",
    "    with open(path_camels / f'periods_{key}.pkl', 'wb') as f:\n",
    "        pickle.dump(dct, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206c885f-3c62-4cea-a6e9-44e00819e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# periodo completo de cada estación\n",
    "periodo_completo = {}\n",
    "for stn in ids:\n",
    "    periodo_completo[stn] = {'start_dates': [pd.Timestamp(estaciones.loc[stn, 'ini_cal'], 10, 1)],\n",
    "                             'end_dates': [pd.Timestamp(estaciones.loc[stn, 'fin_cal'], 9, 30)]}\n",
    "with open(path_camels / f'periods_complete.pkl', 'wb') as f:\n",
    "    pickle.dump(periodo_completo, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e88900-4479-4c1c-985a-a2addfec1de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for id in caudal_esp.columns:\n",
    "    title = '{0} {1} ({3} km²) - {2}'.format(id, *estaciones.loc[id, ['lugar', 'cuenca', 'suprest']])\n",
    "    plot_caudal(caudal_esp[id],\n",
    "                inicios=periodos_ds.sel(id=id, date='start').data,\n",
    "                finales=periodos_ds.sel(id=id, date='end').data,\n",
    "                title=title, \n",
    "                save=f'hidrogramas/{id:04}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba7c03-9007-4675-a07e-65e7934f4ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for period, dct1 in periodos_dct.items():\n",
    "#     for stn, dct2 in dct1.items():\n",
    "#         for date, ls in dct2.items():\n",
    "#             print(period, stn, date, ls[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa43807-3101-4177-b2ab-d48017a09882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7521c94-038e-4e37-9319-cb045830fcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
